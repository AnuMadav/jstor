<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Analysing n-grams with jstor for R • jstor</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">jstor</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/Introduction.html">Introduction to `jstor`</a>
    </li>
    <li>
      <a href="../../articles/automating_file_import.html">Automating File Import</a>
    </li>
    <li>
      <a href="../../analysing-n-grams.html">Analysing n-grams with jstor</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/tklebel/jstor">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Analysing n-grams with jstor for R</h1>
                        <h4 class="author">Thomas Klebel</h4>
            
            <h4 class="date">2018-02-08</h4>
          </div>

    
    
<div class="contents">
<p>The service <a href="http://www.jstor.org/dfr/">DfR</a> by JSTOR offers several ways for text analysis of scientific articles. In this post I will demonstrate how to analyse n-grams which DfR delivers.</p>
<p>Let’s suppose, we are interested in the topic of “inequality” within the discipline of sociology. Social inequality can be considered a prime subject of sociological inquiry. In order to gain some context on the subject, we might be interested to analyse frequently occurring terms.</p>
<p>Our analysis starts at the main page of DfR. We create a dataset by searching for “inequality” and selecting “sociology” as our subject. To trim down the number of articles, we only select articles from 1997 to 2017. After logging in/creating an account, we select unigrams and bigrams. After unzipping the archives to a convenient location, we start our analysis.</p>
<p>Up-front, we need to load some packages. <code>jstor</code> is currently not available from CRAN, but can be installed via <code>devtools</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages("devtools")</span>
<span class="co"># devtools::install_github("tklebel/jstor")</span>

<span class="kw">library</span>(jstor)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(visdat)

<span class="co"># set a lighter theme for plots</span>
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<p>To import the files, we first need to locate them and generate an object with their corresponding paths. The following code assumes that you follow a workflow organised around projects within RStudio (refer to <a href="http://r4ds.had.co.nz/workflow-projects.html" class="uri">http://r4ds.had.co.nz/workflow-projects.html</a> for further information).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># list files</span>
meta_files &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">pattern =</span> <span class="st">"xml"</span>, <span class="dt">full.names =</span> T, <span class="dt">recursive =</span> T)</code></pre></div>
<p>Since we have a decent amount of articles, let’s speed up the process of importing the metadata via parallel processing. <code>jstor_import</code> is a nice wrapper which takes care of setting up the processes and deals with any errors that might occur along the way.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/jstor_import.html">jstor_import</a></span>(meta_files, <span class="dt">out_file =</span> <span class="st">"imported_metadata"</span>, <span class="dt">.f =</span> find_article,
             <span class="dt">files_per_batch =</span> <span class="dv">25000</span>, <span class="dt">cores =</span> <span class="dv">4</span>)
<span class="co">#&gt; Starting to import 23909 file(s).</span>
<span class="co">#&gt; Processing chunk 1/1</span>
<span class="co">#&gt;   |===================================================================| 100%</span>
<span class="co">#&gt; Finished importing 23909 file(s) in 2.54 mins.</span></code></pre></div>
<p>Since <code>jstor_import</code> writes the results to disk, we need to read the metadata from the newly created file.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imported_metadata &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">"imported_metadata-1.csv"</span>, <span class="dt">guess_max =</span> <span class="dv">2000</span>)
imported_metadata</code></pre></div>
<pre><code>## # A tibble: 23,909 x 17
##    basename_id        journal_doi journal_jcode journal_pub_id article_doi
##    &lt;chr&gt;                    &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;      
##  1 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  2 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  3 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  4 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  5 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  6 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  7 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  8 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
##  9 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
## 10 journal-article-1…          NA &lt;NA&gt;          amerjsoci      10.1086/21…
## # ... with 23,899 more rows, and 12 more variables: article_pub_id &lt;chr&gt;,
## #   article_jcode &lt;chr&gt;, article_type &lt;chr&gt;, article_title &lt;chr&gt;,
## #   volume &lt;chr&gt;, issue &lt;chr&gt;, language &lt;chr&gt;, pub_day &lt;chr&gt;,
## #   pub_month &lt;chr&gt;, pub_year &lt;int&gt;, first_page &lt;int&gt;, last_page &lt;int&gt;</code></pre>
<div id="exploration" class="section level1">
<h1 class="hasAnchor">
<a href="#exploration" class="anchor"></a>Exploration</h1>
<p>Before diving into the analysis of ngrams, we might wish to take an explorative look at our metadata.</p>
<p>The first thing to look at are the types of articles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(imported_metadata, <span class="kw">aes</span>(article_type)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><img src="analysing-n-grams_files/figure-html/unnamed-chunk-5-1.png" width="672"></p>
<p>We can see, that the majority of articles are proper “research-articles”, which together with book-reviews and miscellaneous articles amount to ~99% of all articles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imported_metadata <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(article_type, <span class="dt">sort =</span> T) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">perc =</span> scales<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/scales/topics/percent_format">percent</a></span>(n<span class="op">/</span><span class="kw">sum</span>(n)))</code></pre></div>
<pre><code>## # A tibble: 14 x 3
##    article_type         n perc 
##    &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;
##  1 research-article 16289 68.1%
##  2 book-review       4552 19.0%
##  3 misc              2850 11.9%
##  4 other               89 0.4% 
##  5 in-brief            38 0.2% 
##  6 discussion          31 0.1% 
##  7 review-article      25 0.1% 
##  8 announcement        12 0.1% 
##  9 index                9 0.0% 
## 10 editorial            7 0.0% 
## 11 introduction         3 0.0% 
## 12 news                 2 0.0% 
## 13 bibliography         1 0.0% 
## 14 letter               1 0.0%</code></pre>
<p>We must be cautious, however, when using this variable to distinguish articles into categories. In this instance, we have “research-articles” which are actually book-reviews:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imported_metadata <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(article_type <span class="op">==</span><span class="st"> "research-article"</span> <span class="op">&amp;</span><span class="st"> </span><span class="kw">str_detect</span>(article_title, <span class="st">"Book"</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(basename_id, article_title, pub_year)</code></pre></div>
<pre><code>## # A tibble: 190 x 3
##    basename_id                    article_title pub_year
##    &lt;chr&gt;                          &lt;chr&gt;            &lt;int&gt;
##  1 journal-article-10.1086_210272 Book Reviews      1999
##  2 journal-article-10.1086_210273 Book Reviews      1999
##  3 journal-article-10.1086_210274 Book Reviews      1999
##  4 journal-article-10.1086_210275 Book Reviews      1999
##  5 journal-article-10.1086_210276 Book Reviews      1999
##  6 journal-article-10.1086_210278 Book Reviews      1999
##  7 journal-article-10.1086_210279 Book Reviews      1999
##  8 journal-article-10.1086_210280 Book Reviews      1999
##  9 journal-article-10.1086_210281 Book Reviews      1999
## 10 journal-article-10.1086_210283 Book Reviews      1999
## # ... with 180 more rows</code></pre>
<p>For the current demonstration, we want to restrict the type of articles to research articles, therefore we need to steps to remove book reviews and other miscellaneous articles: First, filter by <code>article_type</code>, then remove articles where the title starts with “Book Review”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">research_articles &lt;-<span class="st"> </span>imported_metadata <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(article_type <span class="op">==</span><span class="st"> "research-article"</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">str_detect</span>(article_title, <span class="st">"^Book Review"</span>))</code></pre></div>
<div id="the-moving-wall---filtering-articles-by-time" class="section level2">
<h2 class="hasAnchor">
<a href="#the-moving-wall---filtering-articles-by-time" class="anchor"></a>The moving wall - filtering articles by time</h2>
<p>Since JSTOR has a <a href="https://support.jstor.org/hc/en-us/articles/115004879547-JSTOR-s-Moving-Wall-Archive-vs-Current-Definitions">moving wall</a>, we could take a look at the number of articles per year in our dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">research_articles <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(pub_year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>() </code></pre></div>
<p><img src="analysing-n-grams_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
<p>From this graph we can see an increase in research articles until 2010, after which the number of articles first tapers off, and then drops off sharply. For this reason we should exclude articles from 2015 onward, since the sample might get quite biased toward specific journals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">without_wall &lt;-<span class="st"> </span>research_articles <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(pub_year <span class="op">&lt;</span><span class="st"> </span><span class="dv">2015</span>)</code></pre></div>
</div>
<div id="flagship-journals---filtering-articles-by-journal" class="section level2">
<h2 class="hasAnchor">
<a href="#flagship-journals---filtering-articles-by-journal" class="anchor"></a>Flagship journals - filtering articles by journal</h2>
<p>Since the amount of articles is still rather large for this demonstration, we could select only a few journals. Here, we will look at articles from two leading journals within the discipline, “Journal of Sociology” and “American Sociological Review”. To identify articles from those journals, we need to take a look at the columns “journal_doi”, “journal_jcode”, and “journal_pub_id”. For sociological journals in general, the most common identifier is “journal_jcode”. To demonstrate, we look at the missing proportion for each of the three variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">without_wall <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="kw">contains</span>(<span class="st">"journal"</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/visdat/topics/vis_miss">vis_miss</a></span>()</code></pre></div>
<p><img src="analysing-n-grams_files/figure-html/unnamed-chunk-11-1.png" width="672"></p>
<p>This illustrates rather strikingly, that most of the time our information is in “journal_jcode”, and when it isn’t, it is in “journal_pub_id”.</p>
<p>There are, however, some cases, where there is information in both variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">without_wall <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(journal_jcode) <span class="op">&amp;</span><span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(journal_pub_id))</code></pre></div>
<pre><code>## # A tibble: 33 x 17
##    basename_id        journal_doi journal_jcode journal_pub_id article_doi
##    &lt;chr&gt;                    &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;      
##  1 journal-article-1…          NA j50018924     weatclimsoci   &lt;NA&gt;       
##  2 journal-article-1…          NA j50018924     weatclimsoci   &lt;NA&gt;       
##  3 journal-article-1…          NA j50018924     weatclimsoci   &lt;NA&gt;       
##  4 journal-article-1…          NA j50018924     weatclimsoci   &lt;NA&gt;       
##  5 journal-article-1…          NA j50018924     weatclimsoci   &lt;NA&gt;       
##  6 journal-article-1…          NA j50018924     weatclimsoci   &lt;NA&gt;       
##  7 journal-article-1…          NA j50019839     geneses        &lt;NA&gt;       
##  8 journal-article-1…          NA j50019839     geneses        &lt;NA&gt;       
##  9 journal-article-1…          NA j50019839     geneses        &lt;NA&gt;       
## 10 journal-article-1…          NA j50019839     geneses        &lt;NA&gt;       
## # ... with 23 more rows, and 12 more variables: article_pub_id &lt;chr&gt;,
## #   article_jcode &lt;chr&gt;, article_type &lt;chr&gt;, article_title &lt;chr&gt;,
## #   volume &lt;chr&gt;, issue &lt;chr&gt;, language &lt;chr&gt;, pub_day &lt;chr&gt;,
## #   pub_month &lt;chr&gt;, pub_year &lt;int&gt;, first_page &lt;int&gt;, last_page &lt;int&gt;</code></pre>
<p>Since for those cases, the form without digits (for example “geneses”) is similar to the usual format in “journal_jcode”, we will take the information from “journal_jcode” when it is missing in “journal_pub_id” (which is the most frequent case), and from “journal_pub_id” otherwise.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">without_wall &lt;-<span class="st"> </span>without_wall <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">journal_id =</span> <span class="kw">case_when</span>(<span class="kw">is.na</span>(journal_pub_id) <span class="op">~</span><span class="st"> </span>journal_jcode,
                                <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> </span>journal_pub_id))</code></pre></div>
<p>We can check, if there are any missings left:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">without_wall <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(journal_id) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">is.na</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">any</span>()</code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>After cleaning up the identifier for journals, we can select our two flagship-journals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">flagship_journals &lt;-<span class="st"> </span>without_wall <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(journal_id <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">"amerjsoci"</span>, <span class="st">"amersocirevi"</span>))</code></pre></div>
</div>
</div>
<div id="importing-bigrams" class="section level1">
<h1 class="hasAnchor">
<a href="#importing-bigrams" class="anchor"></a>Importing bigrams</h1>
<blockquote>
<p>Disclaimer: Much of the following analysis was inspired by the book “Text Mining with R” by Julia Silge and David Robinson: <a href="https://www.tidytextmining.com" class="uri">https://www.tidytextmining.com</a></p>
</blockquote>
<p>For this demonstration we will look at bigrams to find the most common pairs of words. Until now, we were only dealing with the metadata, therefore we need a way to link our reduced dataset to the bigram files from DfR. The file name can serve as an identifier to the articles, since it is similar between metadata and n-grams.</p>
<p>First, we list all relevant files on disk.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bigram_files &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="kw">c</span>(<span class="st">"receipt-id-624621-part-001/ngram2/"</span>,
                                    <span class="st">"receipt-id-624621-part-002/ngram2/"</span>),
                           <span class="dt">full.names =</span> T)</code></pre></div>
<p>Next, we select all relevant files from our trimmed down dataset by creating a subset of the files.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create a search pattern by simply pasting together the ids we want to keep</span>
search_pattern &lt;-<span class="st"> </span><span class="kw">paste</span>(flagship_journals<span class="op">$</span>basename_id, <span class="dt">collapse =</span> <span class="st">"|"</span>)

reduced_bigrams &lt;-<span class="st"> </span><span class="kw">str_subset</span>(bigram_files, search_pattern)</code></pre></div>
<p>Equipped with the paths to all files of interest, we import all relevant bigrams to a <code>data.frame</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imported_bigrams &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">file_paths =</span> reduced_bigrams) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">content =</span> <span class="kw">map</span>(file_paths, read_tsv, <span class="dt">col_names =</span> <span class="kw">c</span>(<span class="st">"bigrams"</span>, <span class="st">"n"</span>),
                       <span class="dt">col_types =</span> <span class="kw">list</span>(<span class="kw">col_character</span>(), <span class="kw">col_integer</span>())),
         <span class="dt">basename_id =</span> <span class="kw"><a href="../../reference/get_basename.html">get_basename</a></span>(file_paths),
         <span class="dt">basename_id =</span> <span class="kw">str_replace</span>(basename_id, <span class="st">"-ngram2"</span>, <span class="st">""</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>file_paths) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest</span>()</code></pre></div>
<p>From the 872 articles in our two flagship journals we now have 6729813 bigrams. The bigrams are calculated by JSTOR for each article independently. In order to reduce the sample to the most common bigrams, we have two choices: either to include only terms which occur <em>within each</em> article a given amount of times, or to include terms which occur <em>within all</em> articles a given amount of times. By only including terms which occur more than 5 times in each article, we can drastically reduce the number of terms. However, we might miss some important ones: there might be terms which do not occur repeatedly within articles, but are present in all of them.</p>
<p>For demonstration purposes we are a bit restrictive and include only those terms, which occur at least three times per article.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">top_bigrams &lt;-<span class="st"> </span>imported_bigrams <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(n <span class="op">&gt;=</span><span class="st"> </span><span class="dv">3</span>)</code></pre></div>
<div id="cleaning-up-bigrams" class="section level2">
<h2 class="hasAnchor">
<a href="#cleaning-up-bigrams" class="anchor"></a>Cleaning up bigrams</h2>
<p>When constructing n-grams, DfR uses a stop-word list, which is quite narrow <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. If we would like to restrict the terms a bit further, we could use stopwords from <code>tidytext</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidytext)
bigrams_separated &lt;-<span class="st"> </span>top_bigrams <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">separate</span>(bigrams, <span class="kw">c</span>(<span class="st">"word1"</span>, <span class="st">"word2"</span>), <span class="dt">sep =</span> <span class="st">" "</span>)

bigrams_filtered &lt;-<span class="st"> </span>bigrams_separated <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>word1 <span class="op">%in%</span><span class="st"> </span>stop_words<span class="op">$</span>word) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>word2 <span class="op">%in%</span><span class="st"> </span>stop_words<span class="op">$</span>word)</code></pre></div>
<p>After removing the stopwords we need to consider the fact, that our bigrams were created for each article on its own. In order to analyse them together, we need to count the terms for all articles in combination.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bigram_counts &lt;-<span class="st"> </span>bigrams_filtered <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(word1, word2) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">sum</span>(n)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))

bigram_counts</code></pre></div>
<pre><code>## # A tibble: 106,706 x 3
## # Groups:   word1 [18,152]
##    word1        word2            n
##    &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;
##  1 american     sociological  9593
##  2 sociological review        9198
##  3 university   press         4603
##  4 labor        market        3555
##  5 american     journal       3273
##  6 9            7             3270
##  7 7            6             3260
##  8 10           9             3230
##  9 amsmath      amsxtra       3192
## 10 begin        document      3192
## # ... with 106,696 more rows</code></pre>
<p>From the first few terms we can see, that there are still many terms which are not very interesting for our analysis. The terms “american” and “sociological” are simply part of the title of a journal we selected (American Sociological Review). To clean the terms up, we can employ different approaches. One is to simply filter the terms we wish to exclude:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bigram_counts_clean &lt;-<span class="st"> </span>bigram_counts <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unite</span>(bigram, word1, word2, <span class="dt">sep =</span> <span class="st">" "</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>bigram <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">"american sociological"</span>, <span class="st">"sociological review"</span>,
                        <span class="st">"university press"</span>, <span class="st">"american journal"</span>,
                        <span class="st">"journal sociology"</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">separate</span>(bigram, <span class="kw">c</span>(<span class="st">"word1"</span>, <span class="st">"word2"</span>))</code></pre></div>
<p>We will look at another approach after plotting our bigrams.</p>
</div>
</div>
<div id="visualize-relationships" class="section level1">
<h1 class="hasAnchor">
<a href="#visualize-relationships" class="anchor"></a>Visualize relationships</h1>
<p>When analyzing bigrams, we might want to look at the relationships between common terms. For this we can leverage the power of <a href="http://igraph.org/r/">igraph</a> and <a href="https://cran.r-project.org/web/packages/ggraph/index.html">ggraph</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(igraph)
<span class="kw">library</span>(ggraph)</code></pre></div>
<p>First, we only keep the most common terms and then convert our <code>data.frame</code> to an <code>igraph</code>-object. <a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bigram_graph &lt;-<span class="st"> </span>bigram_counts_clean <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(n <span class="op">&gt;</span><span class="st"> </span><span class="dv">500</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/igraph/topics/graph_from_data_frame">graph_from_data_frame</a></span>()

bigram_graph</code></pre></div>
<pre><code>## IGRAPH 4cc5ba6 DN-- 170 161 -- 
## + attr: name (v/c), n (e/n)
## + edges from 4cc5ba6 (vertex names):
##  [1] labor                 -&gt;market   9                     -&gt;7       
##  [3] 7                     -&gt;6        10                    -&gt;9       
##  [5] amsmath               -&gt;amsxtra  begin                 -&gt;document
##  [7] declaremathsizes      -&gt;10       declaretextfontcommand-&gt;textcyr 
##  [9] documentclass         -&gt;aastex   encodingdefault       -&gt;ot2     
## [11] newcommand            -&gt;cyr      ot1                   -&gt;fontenc 
## [13] ot2                   -&gt;ot1      pagestyle             -&gt;empty   
## [15] portland              -&gt;xspace  
## + ... omitted several edges</code></pre>
<p>For plotting, we will use a simple plotting function, adapted from <a href="https://www.tidytextmining.com/ngrams.html#visualizing-a-network-of-bigrams-with-ggraph" class="uri">https://www.tidytextmining.com/ngrams.html#visualizing-a-network-of-bigrams-with-ggraph</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">plot_bigrams &lt;-<span class="st"> </span><span class="cf">function</span>(igraph_df, <span class="dt">seed =</span> <span class="dv">2016</span>) {
  <span class="kw">set.seed</span>(seed)
  
  a &lt;-<span class="st"> </span>grid<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/grid/topics/arrow">arrow</a></span>(<span class="dt">type =</span> <span class="st">"closed"</span>, <span class="dt">length =</span> <span class="kw">unit</span>(.<span class="dv">15</span>, <span class="st">"inches"</span>))

  <span class="kw"><a href="http://www.rdocumentation.org/packages/ggraph/topics/ggraph">ggraph</a></span>(igraph_df, <span class="dt">layout =</span> <span class="st">"fr"</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggraph/topics/geom_edge_link">geom_edge_link</a></span>(<span class="kw">aes</span>(<span class="dt">edge_alpha =</span> n), <span class="dt">show.legend =</span> <span class="ot">FALSE</span>,
                   <span class="dt">arrow =</span> a, <span class="dt">end_cap =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/ggraph/topics/geometry">circle</a></span>(.<span class="dv">07</span>, <span class="st">'inches'</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggraph/topics/geom_node_point">geom_node_point</a></span>(<span class="dt">color =</span> <span class="st">"lightblue"</span>, <span class="dt">size =</span> <span class="dv">4</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggraph/topics/geom_node_text">geom_node_text</a></span>(<span class="kw">aes</span>(<span class="dt">label =</span> name), <span class="dt">repel =</span> T) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggraph/topics/theme_graph">theme_graph</a></span>()
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_bigrams</span>(bigram_graph)</code></pre></div>
<p><img src="analysing-n-grams_files/figure-html/unnamed-chunk-28-1.png" width="1152"> Very obvious is a group of nodes which are not relevant to the topic of inequality. They come from LaTeX documents and somehow made their way into the original dataset. However, since they are more common than most of the other terms, they are quite easy to remove. We can look at the nodes/vertices of our graph with <code><a href="http://www.rdocumentation.org/packages/igraph/topics/V">V(bigram_graph)</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/igraph/topics/V">V</a></span>(bigram_graph)</code></pre></div>
<pre><code>## + 170/170 vertices, named, from 4cc5ba6:
##   [1] labor                  9                      7                     
##   [4] 10                     amsmath                begin                 
##   [7] declaremathsizes       declaretextfontcommand documentclass         
##  [10] encodingdefault        newcommand             ot1                   
##  [13] ot2                    pagestyle              portland              
##  [16] renewcommand           rmdefault              sfdefault             
##  [19] textcyr                usepackage             6                     
##  [22] aastex                 amsbsy                 amsfonts              
##  [25] amssymb                amsxtra                bm                    
##  [28] cyr                    document               empty                 
## + ... omitted several vertices</code></pre>
<p>The first node, “labor”, is relevant to us, but all other nodes from 2 to at least 40 are clearly irrelevant. We can remove them by simple subtraction:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bigram_graph_clean &lt;-<span class="st"> </span>bigram_graph <span class="op">-</span><span class="st"> </span><span class="dv">2</span><span class="op">:</span><span class="dv">40</span>
bigram_graph_clean</code></pre></div>
<pre><code>## IGRAPH 969ed3c DN-- 131 105 -- 
## + attr: name (v/c), n (e/n)
## + edges from 969ed3c (vertex names):
##  [1] labor     -&gt;market     labor     -&gt;force      0         -&gt;0         
##  [4] table     -&gt;2          1         -&gt;1          income    -&gt;inequality
##  [7] black     -&gt;white      table     -&gt;1          table     -&gt;3         
## [10] social    -&gt;capital    model     -&gt;1          model     -&gt;2         
## [13] african   -&gt;american   0         -&gt;1          human     -&gt;capital   
## [16] african   -&gt;americans  table     -&gt;4          1         -&gt;2         
## [19] model     -&gt;3          racial    -&gt;ethnic     individual-&gt;level     
## [22] civil     -&gt;rights     cross     -&gt;national  
## + ... omitted several edges</code></pre>
<p>Another apparent group is a combination of “table” or “figure” with digits. This evidently comes from tables or figures in the papers and might suggest, that the articles in our sample quite frequently employ quantitative methods, where figures and tables are very common. For the analysis at hand however, we might remove them, along with a few other irrelevant terms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bigram_graph_clean &lt;-<span class="st"> </span>bigram_graph_clean <span class="op">-</span><span class="st"> </span><span class="kw">c</span>(<span class="st">"table"</span>, <span class="st">"model"</span>,
                                             <span class="kw">as.character</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>),
                                             <span class="st">"xd"</span>, <span class="st">"rh"</span>, <span class="st">"landscape"</span>, <span class="st">"00"</span>,
                                             <span class="st">"figure"</span>, <span class="st">"review"</span>, <span class="st">"79"</span>,
                                             <span class="st">"http"</span>, <span class="st">"www"</span>, <span class="st">"000"</span>, <span class="st">"01"</span>)</code></pre></div>
<p>After cleaning up a bit, we can take a fresh look at our bigrams.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_bigrams</span>(bigram_graph_clean, <span class="dv">234</span>)</code></pre></div>
<p><img src="analysing-n-grams_files/figure-html/unnamed-chunk-32-1.png" width="1152"></p>
<p>The figure is still far from perfect (“eco” -&gt; “nomic” should clearly be one term), but we can begin to analyse our network.</p>
<p>The most frequent bigrams are now “labor market”, “labor force”, and “income inequality”, which are not very surprising given that most individuals in capitalist societies need to supply their work in exchange for income. For this reason, the labor market and its stratification is a prime subject of the sociological inquiry into inequality.</p>
<p>A few further key dimension of sociological analysis are apparent from the graph: gender, race/ethnicity, occupational and socioeconomic status. That we find many terms to be associated with the term “social” seems quite likely given the discipline’s subject.</p>
<p>At least two surprising results should be pointed out. First, it is not evident how the terms “ethnic” and “racial” are connected. They do not form a typical term like “social capital”, “middle class” or similar, nor could they be considered a dichotomy like “black” and “white” which are often included in tables from regressions. Second, there is a group of nodes around the term “university”: university -&gt; chicago, university -&gt; california, harvard -&gt; university, etc. At least two explanations seem plausible: either, many books are being cited which are in some way associated with those universities (“The University of Chicago Press” is the largest university press in the United States), or many researchers who publish in the two flagship-journals we selected are affiliated with those four universities: Harvard, Chicago, Cambridge and California.</p>
</div>
<div id="comparison-over-time" class="section level1">
<h1 class="hasAnchor">
<a href="#comparison-over-time" class="anchor"></a>Comparison over time</h1>
<p>Besides looking at the overall relationship of bigrams, we could be interested in the development over time of specific terms. Here, we want to look at how often “labor market” and “income inequality” appear from year to year.</p>
<p>For this, we need to join our bigrams with the metadata.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">time_bigrams &lt;-<span class="st"> </span>top_bigrams <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(flagship_journals, <span class="dt">by =</span> <span class="st">"basename_id"</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(bigrams, n, pub_year)

<span class="kw">head</span>(time_bigrams)</code></pre></div>
<pre><code>##             bigrams  n pub_year
## 1    private sector 92     1998
## 2 market transition 68     1998
## 3               3 t 38     1998
## 4              1 00 37     1998
## 5 journal sociology 34     1998
## 6      state sector 34     1998</code></pre>
<p>Again, we need to sum up the counts, but this time grouped by year:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">time_bigrams &lt;-<span class="st"> </span>time_bigrams <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(bigrams, pub_year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">sum</span>(n)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))

time_bigrams</code></pre></div>
<pre><code>## # A tibble: 248,725 x 3
## # Groups:   bigrams [157,266]
##    bigrams               pub_year     n
##    &lt;chr&gt;                    &lt;int&gt; &lt;int&gt;
##  1 0 0                       2004  1071
##  2 et al                     2014   916
##  3 women s                   2006   885
##  4 american sociological     2014   860
##  5 sociological review       2014   814
##  6 u s                       2014   793
##  7 et al                     2011   792
##  8 et al                     2013   748
##  9 et al                     2010   691
## 10 et al                     2012   687
## # ... with 248,715 more rows</code></pre>
<p>We now only keep the two terms of interest and plot them in a simple chart.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># filter the terms of interest</span>
time_comparison &lt;-<span class="st"> </span>time_bigrams <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(bigrams <span class="op">==</span><span class="st"> "labor market"</span> <span class="op">|</span><span class="st"> </span>bigrams <span class="op">==</span><span class="st"> "income inequality"</span>)

<span class="kw">ggplot</span>(time_comparison, <span class="kw">aes</span>(pub_year, n, <span class="dt">colour =</span> bigrams)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> scales<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/scales/topics/pretty_breaks">pretty_breaks</a></span>(<span class="dv">7</span>))</code></pre></div>
<p><img src="analysing-n-grams_files/figure-html/unnamed-chunk-35-1.png" width="960"></p>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>When reading this data without <code>guess_max = 2000</code>, a warning is raised because the column type was not recognized properly for one column. Increasing <code>guess_max</code> helped in this instance.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>for more information see the <a href="http://www.jstor.org/dfr/about/technical-specifications">technical specifications</a> on their page<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>If you are unfamiliar with graph theory, just take a look at Wikipedia: <a href="https://en.wikipedia.org/wiki/Graph_theory">Graph Theory</a>.<a href="#fnref3">↩</a></p></li>
</ol>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#exploration">Exploration</a><ul class="nav nav-pills nav-stacked">
<li><a href="#the-moving-wall---filtering-articles-by-time">The moving wall - filtering articles by time</a></li>
      <li><a href="#flagship-journals---filtering-articles-by-journal">Flagship journals - filtering articles by journal</a></li>
      </ul>
</li>
      <li>
<a href="#importing-bigrams">Importing bigrams</a><ul class="nav nav-pills nav-stacked">
<li><a href="#cleaning-up-bigrams">Cleaning up bigrams</a></li>
      </ul>
</li>
      <li><a href="#visualize-relationships">Visualize relationships</a></li>
      <li><a href="#comparison-over-time">Comparison over time</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Thomas Klebel.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
